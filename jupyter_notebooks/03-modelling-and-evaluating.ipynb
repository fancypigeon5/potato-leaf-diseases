{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# Modelling and Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Answer business requirement 2: \n",
    "    - The client is interested in predicting whether a potato leaf is healthy or diseased, and if diseased, identifying the specific disease present.\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- inputs/leaves_dataset/leaf_images/train\n",
    "- inputs/leaves_dataset/leaf_images/test\n",
    "- inputs/leaves_dataset/leaf_images/validation\n",
    "- image shape embeddings.\n",
    "\n",
    "## Outputs\n",
    "- Images distribution plot in train, validation, and test set.\n",
    "- Image augmentation.\n",
    "- Class indices to change prediction inference in labels.\n",
    "- Machine learning model creation and training.\n",
    "- Save model.\n",
    "- Learning curve plot for model performance.\n",
    "- Model evaluation on pickle file.\n",
    "- Prediction on the random image file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRwFQLlmwrl9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2oPUd1K_qCr"
   },
   "source": [
    "# Import regular packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oqqga261_w4N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRwFQLlmwrl9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2oPUd1K_qCr"
   },
   "source": [
    "# Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8SooBUDWVIQK"
   },
   "outputs": [],
   "source": [
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ7j8jHhmYDD"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(cwd))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b107Zs3TmYDD"
   },
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRwFQLlmwrl9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czVrQtLccTJb"
   },
   "source": [
    "## Set input directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx2ZqnpDcY2H"
   },
   "source": [
    "Set train, validation and test paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5eucaA9M6qz1"
   },
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/leaves_dataset/leaf_images'\n",
    "train_path = my_data_dir + '/train'\n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czVrQtLccTJb"
   },
   "source": [
    "## Set output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v2'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czVrQtLccTJb"
   },
   "source": [
    "## Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntzIpcxb3oIE"
   },
   "outputs": [],
   "source": [
    "\n",
    "labels = os.listdir(train_path)\n",
    "n_labels = len(labels)\n",
    "\n",
    "print(\n",
    "    f\"Project Labels: {labels}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSTKDM0XvuVu"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQ0p1nYJ_3sx"
   },
   "source": [
    "# Number of images in train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeOv0tCn3_Y_"
   },
   "outputs": [],
   "source": [
    "lst_freq = []\n",
    "for folder in ['train', 'validation', 'test']:\n",
    "    for label in labels:\n",
    "        lst_freq.append(\n",
    "            pd.Series(data={'Set': folder,\n",
    "                            'Label': label,\n",
    "                            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))}\n",
    "                      )\n",
    "        )\n",
    "        print(\n",
    "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
    "df_freq = pd.DataFrame(lst_freq)\n",
    "print(\"\\n\")\n",
    "print(df_freq)\n",
    "print(\"\\n\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def balance_sample_images(src_folder, dest_folder, target_count, label_folder):\n",
    "    images = os.listdir(src_folder + '/' + label_folder)\n",
    "    oversampleimggen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          )\n",
    "    \n",
    "    save_prefix = 'aug-'\n",
    "    aug_gen=oversampleimggen.flow_from_directory(src_folder, batch_size=1, shuffle=True, seed=42, classes=[label_folder],\n",
    "                                    save_to_dir=dest_folder, save_prefix=save_prefix, color_mode='rgb',\n",
    "                                    save_format='jpg')\n",
    "    print('Augmenting images for class:', label_folder)\n",
    "\n",
    "    aug_img_count = 0\n",
    "    while aug_img_count < target_count:\n",
    "        save_prefix = 'aug-' + str(aug_img_count) + '-'\n",
    "        image = next(aug_gen)\n",
    "        aug_img_count += 1\n",
    "    print('Total Augmented images created= ', aug_img_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def balance_sample_images_min(src_folder, dest_folder, target_count, label_folder):\n",
    "    images = os.listdir(src_folder + '/' + label_folder)\n",
    "    oversampleimggen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                          vertical_flip=True\n",
    "                                          )\n",
    "    \n",
    "    save_prefix = 'aug-'\n",
    "    aug_gen=oversampleimggen.flow_from_directory(src_folder, batch_size=1, shuffle=True, seed=42, classes=[label_folder],\n",
    "                                    save_to_dir=dest_folder, save_prefix=save_prefix, color_mode='rgb',\n",
    "                                    save_format='jpg')\n",
    "    print('Augmenting images for class:', label_folder)\n",
    "\n",
    "    if len(images) < target_count:\n",
    "        delta = target_count - len(images)\n",
    "        aug_img_count = 0\n",
    "        while aug_img_count < delta:\n",
    "            save_prefix = 'aug-' + str(aug_img_count) + '-'\n",
    "            image = next(aug_gen)\n",
    "            aug_img_count += 1\n",
    "        print('Total Augmented images created= ', aug_img_count)\n",
    "        for i in range(len(images)):\n",
    "            shutil.copy(src_folder + '/' + label_folder + '/' + images[i], dest_folder + '/' + images[i])\n",
    "    else:\n",
    "        for i in range(len(images)):\n",
    "            shutil.copy(src_folder + '/' + label_folder + '/' + images[i], dest_folder + '/' + images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_path = my_data_dir + '/balanced/train_balanced'\n",
    "if 'balanced' in os.listdir(work_dir + '/inputs/leaves_dataset/leaf_images'):\n",
    "    shutil.rmtree(train_balanced_path)\n",
    "\n",
    "os.makedirs(name=train_balanced_path)\n",
    "\n",
    "label_folders = os.listdir(train_path)\n",
    "avg_images = math.floor(sum(len(os.listdir(train_path + '/' + f)) for f in label_folders)/len(label_folders))\n",
    "print(f\"avg number of images in a label folder: {avg_images}\")\n",
    "target_count = 300\n",
    "for label_folder in label_folders:\n",
    "    dest_folder = train_balanced_path + '/' + label_folder\n",
    "    os.makedirs(name=dest_folder, exist_ok=True)\n",
    "    label_folder_path = train_path\n",
    "    balance_sample_images_min(label_folder_path, dest_folder, target_count, label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_freq = []\n",
    "for folder in ['balanced/train_balanced', 'train', 'validation', 'test']:\n",
    "    for label in labels:\n",
    "        lst_freq.append(\n",
    "            pd.Series(data={'Set': folder,\n",
    "                            'Label': label,\n",
    "                            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))}\n",
    "                      )\n",
    "        )\n",
    "        print(\n",
    "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
    "df_freq = pd.DataFrame(lst_freq)\n",
    "print(\"\\n\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution_balanced.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp4l-B11vCiP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qved3ALYLrng"
   },
   "source": [
    "# Image data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRwFQLlmwrl9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=10,\n",
    "                                          width_shift_range=0.1,      \n",
    "                                          height_shift_range=0.1,   \n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Augment training image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_balanced_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=True,\n",
    "                                                     seed=42\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cAwum1tWsmz"
   },
   "source": [
    "* ### Augment validation image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='categorical',\n",
    "                                                                        shuffle=True,\n",
    "                                                                        seed=42\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxDzlWdBXGGI"
   },
   "source": [
    "* ### Augment test image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot augmented training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(train_set)\n",
    "    print(img.shape)  # (1,1500,1500,3)\n",
    "    print(label.shape)  # (1,5)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot augmented validation and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(validation_set)\n",
    "    print(img.shape)  # (1,1500,1500,3)\n",
    "    print(label.shape)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = next(test_set)\n",
    "    print(img.shape)  # (1,1500,1500,3)\n",
    "    print(label.shape)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxFqIpblnaDI"
   },
   "source": [
    "## Save class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c60wT9Nvnaht"
   },
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp4l-B11vCiP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qved3ALYLrng"
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRwFQLlmwrl9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lp60ceJkvFab"
   },
   "source": [
    "## ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Import model packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3em0FUWzBTCF"
   },
   "outputs": [],
   "source": [
    "def create_tf_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), strides= (2, 2), activation='relu', ))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides= (2, 2), activation='relu', ))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides= (2, 2), activation='relu', ))\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides= (2, 2), activation='relu', ))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(len(train_set.class_indices), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Model Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0fnaUSeBTFy"
   },
   "outputs": [],
   "source": [
    "input_shape = image_shape\n",
    "create_tf_model(input_shape=input_shape).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Early Stopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "49bP61QYBTMF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-Sv_Nlfzr5F"
   },
   "source": [
    "## Fit model for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHD-ggqiB3zV"
   },
   "outputs": [],
   "source": [
    "model = create_tf_model(input_shape=input_shape)\n",
    "model.fit(train_set,\n",
    "          epochs=300,\n",
    "          validation_data=validation_set,\n",
    "          callbacks=[early_stop],\n",
    "          verbose=1          \n",
    "          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtuBjjzFiQRh"
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelversion = 4\n",
    "model_file_path = f'{file_path}/model_V{modelversion}'\n",
    "if f'model_V{modelversion}' in os.listdir(work_dir + '/' + file_path):\n",
    "    print('Old version is already available createing a new version.')\n",
    "    while f'model_V{modelversion}' in os.listdir(work_dir + '/' + file_path):\n",
    "        modelversion += 1\n",
    "        model_file_path = f'{file_path}/model_V{modelversion}'\n",
    "\n",
    "os.makedirs(name=model_file_path)\n",
    "model.save(f'{model_file_path}/disease_identification_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp4l-B11vCiP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qved3ALYLrng"
   },
   "source": [
    "# Model Performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRwFQLlmwrl9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uESgICbOztUi"
   },
   "source": [
    "## Model learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inzjI5Ve2UVi"
   },
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "losses[['loss', 'val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(f'{model_file_path}/model_training_losses.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig(f'{model_file_path}/model_training_acc.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_I41227LlqtV"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(f'{model_file_path}/disease_identification_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Auo3VPdvmVL1"
   },
   "source": [
    "Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dsaUbtSlK8V"
   },
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save evaluation pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f'{model_file_path}/evaluation.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtuBjjzFiQRh"
   },
   "source": [
    "## Predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt6Esizw677F"
   },
   "source": [
    "Load a random image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oz-NL2mXaczH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 4\n",
    "label = labels[1]\n",
    "\n",
    "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
    "                           target_size=image_shape, color_mode='rgb')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "pil_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QweywGMLm_0V"
   },
   "source": [
    "Convert image to array and prepare for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwoIvJWQcitQ"
   },
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)/255\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCS7g3CenGJE"
   },
   "source": [
    "Predict class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkFoAMtUdEO2"
   },
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class_index = np.argmax(pred_proba)\n",
    "pred_class = target_map[pred_class_index]\n",
    "\n",
    "print(f'Probabilities: {pred_proba}')\n",
    "print(f'Predicted probability: {pred_proba[pred_class_index]}')\n",
    "print(f'Predicted class: {pred_class}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def confusion_matrix_and_report(path,pipeline,label_map):\n",
    "  # the prediction comes in a one hot encoded format\n",
    "  labels = len(os.listdir(path))\n",
    "  batch_size = 0\n",
    "  for label in label_map:\n",
    "    batch_size += len(os.listdir(path + '/' + label))\n",
    "  set = ImageDataGenerator(rescale=1./255).flow_from_directory(path, target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical',\n",
    "                                                                  shuffle=False\n",
    "                                                              )\n",
    "  X, y = next(set)\n",
    "  prediction = pipeline.predict(X)\n",
    "  # so we take the index from the highest probability, which is the \"winner\" or predicted class\n",
    "  prediction = np.argmax(prediction, axis=1)\n",
    "  \n",
    "  # we also take the index from the highest probability from the actual values\n",
    "  y = np.argmax(y, axis=1)\n",
    "\n",
    "  print('---  Confusion Matrix  ---')\n",
    "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "        columns=[ [\"Actual \" + sub for sub in label_map] ], \n",
    "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
    "        ))\n",
    "  print(\"\\n\")\n",
    "\n",
    "  print('---  Classification Report  ---')\n",
    "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")\n",
    "\n",
    "\n",
    "def clf_performance(train_balanced_path, test_path, validation_path,pipeline,label_map):\n",
    "\n",
    "  print(\"#### Train Set #### \\n\")\n",
    "  confusion_matrix_and_report(train_balanced_path,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Validation Set #### \\n\")\n",
    "  confusion_matrix_and_report(test_path,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Test Set ####\\n\")\n",
    "  confusion_matrix_and_report(validation_path,pipeline,label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = [str(x) for x in train_set.class_indices.keys()]\n",
    "\n",
    "clf_performance(train_balanced_path, test_path, val_path, model, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RtitT7v-xv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "potatoes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
